<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Susan Eileen Fox">
<meta name="dcterms.date" content="2025-11-14">

<title>Homework 4 – Vision Readings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-226bd0f977fa82dfae4534cac220d79a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-9011e249e8d359b0658fa71d60c1fa6f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Vision Readings</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Homework 4</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Susan Eileen Fox </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 14, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#question-1-working-with-mediapipe-models-part-one" id="toc-question-1-working-with-mediapipe-models-part-one" class="nav-link" data-scroll-target="#question-1-working-with-mediapipe-models-part-one">Question 1: Working with Mediapipe models, part one</a>
  <ul class="collapse">
  <li><a href="#specifications-for-question-1" id="toc-specifications-for-question-1" class="nav-link" data-scroll-target="#specifications-for-question-1">Specifications for Question 1</a></li>
  </ul></li>
  <li><a href="#question-2-working-with-mediapipe-models-part-two" id="toc-question-2-working-with-mediapipe-models-part-two" class="nav-link" data-scroll-target="#question-2-working-with-mediapipe-models-part-two">Question 2: Working with Mediapipe models, part two</a>
  <ul class="collapse">
  <li><a href="#specifications-for-question-2" id="toc-specifications-for-question-2" class="nav-link" data-scroll-target="#specifications-for-question-2">Specifications for Question 2</a></li>
  </ul></li>
  <li><a href="#question-3-data-preparation-for-image-classification" id="toc-question-3-data-preparation-for-image-classification" class="nav-link" data-scroll-target="#question-3-data-preparation-for-image-classification">Question 3: Data preparation for image classification</a>
  <ul class="collapse">
  <li><a href="#specifications-for-question-3" id="toc-specifications-for-question-3" class="nav-link" data-scroll-target="#specifications-for-question-3">Specifications for Question 3</a></li>
  </ul></li>
  <li><a href="#question-4-training-a-cnn" id="toc-question-4-training-a-cnn" class="nav-link" data-scroll-target="#question-4-training-a-cnn">Question 4: Training a CNN</a>
  <ul class="collapse">
  <li><a href="#specifications-for-question-4" id="toc-specifications-for-question-4" class="nav-link" data-scroll-target="#specifications-for-question-4">Specifications for Question 4</a></li>
  </ul></li>
  <li><a href="#question-5-experimenting-with-object-detection-and-segmentation-models" id="toc-question-5-experimenting-with-object-detection-and-segmentation-models" class="nav-link" data-scroll-target="#question-5-experimenting-with-object-detection-and-segmentation-models">Question 5: Experimenting with Object Detection and Segmentation Models</a>
  <ul class="collapse">
  <li><a href="#specifications-for-question-5" id="toc-specifications-for-question-5" class="nav-link" data-scroll-target="#specifications-for-question-5">Specifications for Question 5</a></li>
  </ul></li>
  <li><a href="#question-6-evaluating-generative-ai-for-images" id="toc-question-6-evaluating-generative-ai-for-images" class="nav-link" data-scroll-target="#question-6-evaluating-generative-ai-for-images">Question 6: Evaluating Generative AI for images</a></li>
  <li><a href="#what-to-hand-in" id="toc-what-to-hand-in" class="nav-link" data-scroll-target="#what-to-hand-in">What to hand in</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="overview" class="level1">
<h1>Overview</h1>
<p><strong>This assignment may be completed individually, or in teams of 2 or 3. Form a team in Github.</strong></p>
<ul>
<li>Do not share or borrow solutions from students outside your team members.</li>
<li>Do not use AI assistants to generate code for you.</li>
<li><strong>Do</strong> ask preceptors and instructors for help with the code, including what to write and debugging.</li>
<li><strong>Do</strong> ask peers or AI assistants for help in understanding error messages, but not for help in writing or debugging your work.</li>
</ul>
<p>This homework assignment will ask you to demonstrate your skills at working with machine learning for computer vision tasks. The list of topics for this assignment include:</p>
<ul>
<li>Using Mediapipe models to identify gestures, body or face poses</li>
<li>Training a convolutional neural network to classify images</li>
<li>Working with an object detection or segmentation model</li>
<li>Analyzing the result of image-generating models</li>
</ul>
<p><strong>To hand in:</strong> You will use the Homework 4 Github Assignment to set up this assignment, and to <em>push</em> your code to save it to the cloud, to hand it in. Note that all your work will go into a single file for this assignment. Starter code files will be provided. Additionally, you will use one or two Google Colab notebooks, and will submit a link to them in your Github repo (as directed below)</p>
<p><strong>Handling images, videos and models:</strong></p>
<ul>
<li>I will provide in the Github assignment just those images you need to have to do this assignment</li>
<li>Because videos are often too large to be stored in Github, you will need to copy any video files to your project and <strong>do not</strong> add them to those managed by Git</li>
<li>Models are even larger than videos, thus you will need to copy any existingmodels to your project and <strong>not</strong> add them to Git</li>
</ul>
</section>
<section id="question-1-working-with-mediapipe-models-part-one" class="level1">
<h1>Question 1: Working with Mediapipe models, part one</h1>
<p>For this question, you will choose one of the four Mediapipe models, and demo programs, described in Chapter 8.1 and [ICA 16](https://comp-194-vision-master.github.io/PublishedMaterials/In-Class-Activities/ICA16-UsingMLModels.html.</p>
<p>Pick one, and complete the extensions described in the activity. These extensions involve pulling apart the <code>detect-result</code> to get coordinates of features it has identified, and then using some threshold or calculations on those features to decide what is happening in the image. You then print the outcome (you can also display it on the image along with the visualization of the results, if you like, but it isn’t required).</p>
<section id="specifications-for-question-1" class="level2">
<h2 class="anchored" data-anchor-id="specifications-for-question-1">Specifications for Question 1</h2>
<p><strong>Base specifications:</strong></p>
<ul>
<li>Extensions are added to the designated helper function (<code>findFacing</code>, <code>findEyes</code>, <code>findHandPose</code>, or <code>findHandsUp</code>)</li>
<li>The function includes code that extracts appropriate values from the detection result</li>
<li>The function implements reasonable calculations and/or thresholds for deciding what is happening in the image
<ul>
<li>facing left, right, or forward for the face detection program</li>
<li>eyes open or shut for the facial landmark program</li>
<li>hand in fist or open palm (vertical, fingers pointing upward) for hand landmark program</li>
<li>hands above head or below/even with head for body pose program</li>
</ul></li>
<li>Function prints or displays a message correctly describing the result (some inaccuracy is okay)</li>
</ul>
<p><strong>Extended specifications:</strong></p>
<ul>
<li>Code includes a triple-quoted <em>docstring</em> that describes the function’s input, purpose, and results</li>
<li>Student name is at the top of the file</li>
<li>Any completed TODO comments have been removed</li>
<li>File format has appropriate style:
<ul>
<li><code>import</code> statements at the top</li>
<li>then function definitions with no script elements</li>
<li>then the main script, all insidde the <code>if __name__ == '__main__':</code> statement</li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<ul>
<li>To receive a gold rating, complete at least 5 specifications, at least 4 of them base</li>
<li>To receive a silver rating, complete at least 4 specifications, at least 3 of them base</li>
<li>To receive a bronze rating, complete at least 3 specifications, at least 2 of them base</li>
</ul>
</section>
</section>
<section id="question-2-working-with-mediapipe-models-part-two" class="level1">
<h1>Question 2: Working with Mediapipe models, part two</h1>
<p>For this question, you will choose <strong>a different one</strong> of the four Mediapipe models, and demo programs, described in Chapter 8.1 and <a href="https://comp-194-vision-master.github.io/PublishedMaterials/In-Class-Activities/ICA16-UsingMLModels.html">ICA 16</a>.</p>
<p>Pick one, and complete the extensions described in the activity. These extensions involve pulling apart the <code>detect-result</code> to get coordinates of features it has identified, and then using some threshold or calculations on those features to decide what is happening in the image. You then print the outcome (you can also display it on the image along with the visualization of the results, if you like, but it isn’t required).</p>
<section id="specifications-for-question-2" class="level2">
<h2 class="anchored" data-anchor-id="specifications-for-question-2">Specifications for Question 2</h2>
<p><strong>Base specifications:</strong></p>
<ul>
<li>Extensions are added to the designated helper function (<code>findFacing</code>, <code>findEyes</code>, <code>findHandPose</code>, or <code>findHandsUp</code>)</li>
<li>The function includes code that extracts appropriate values from the detection result</li>
<li>The function implements reasonable calculations and/or thresholds for deciding what is happening in the image
<ul>
<li>facing left, right, or forward for the face detection program</li>
<li>eyes open or shut for the facial landmark program</li>
<li>hand in fist or open palm (vertical, fingers pointing upward) for hand landmark program</li>
<li>hands above head or below/even with head for body pose program</li>
</ul></li>
<li>Function prints or displays a message correctly describing the result (some inaccuracy is okay)</li>
</ul>
<p><strong>Extended specifications:</strong></p>
<ul>
<li>Code includes a triple-quoted <em>docstring</em> that describes the function’s input, purpose, and results</li>
<li>Student name is at the top of the file</li>
<li>Any completed TODO comments have been removed</li>
<li>File format has appropriate style:
<ul>
<li><code>import</code> statements at the top</li>
<li>then function definitions with no script elements</li>
<li>then the main script, all insidde the <code>if __name__ == '__main__':</code> statement</li>
</ul></li>
</ul>
<p><strong>Ratings:</strong></p>
<ul>
<li>To receive a gold rating, complete at least 5 specifications, at least 4 of them base</li>
<li>To receive a silver rating, complete at least 4 specifications, at least 3 of them base</li>
<li>To receive a bronze rating, complete at least 3 specifications, at least 2 of them base</li>
</ul>
</section>
</section>
<section id="question-3-data-preparation-for-image-classification" class="level1">
<h1>Question 3: Data preparation for image classification</h1>
<p>In ICA 17, you work through an example of training a CNN to perform image classification. The second half of the activity asks you to repeat the process for a new dataset.</p>
<p>Open the <a href="https://colab.research.google.com/drive/1E5RhAK0TgbZQgZwJBgpTgY8Njy_fTXZk?usp=sharing">ICA Colab Notebook</a>, make a copy for your team, and work through these sections:</p>
<ul>
<li>Step 1: Reading in the data</li>
<li>Step 2: Examining the data</li>
<li>Step 3: Preprocessing the data</li>
</ul>
<section id="specifications-for-question-3" class="level2">
<h2 class="anchored" data-anchor-id="specifications-for-question-3">Specifications for Question 3</h2>
<p><strong>Base specifications:</strong></p>
<ul>
<li>Code block successfully reads in both training and validation data (using the <code>as_supervised</code> input)</li>
<li>Code block displays 3x3 grid of sample images from the start of the dataset</li>
<li>Code block correctly creates the <code>preprocess</code> mini-model to adapt the dataset</li>
<li>Code block correctly applies the <code>preprocess</code> mini-model to both training and validation sets</li>
</ul>
<p><strong>Extended specifications:</strong></p>
<ul>
<li>A link to the Colab Notebook is added to the README.md file in Github</li>
<li>Student names are added to the top of the Colab notebook</li>
<li>Any completed TODO comments have been removed</li>
</ul>
<p><strong>Ratings:</strong></p>
<ul>
<li>To receive a gold rating, complete at least 5 specifications, at least 3 of which are base</li>
<li>To receive a silver rating, complete at least 4 specifications, at least 3 of which are base</li>
<li>To receive a bronze rating, complete at least 3 specifications, at least 2 of which are base</li>
</ul>
</section>
</section>
<section id="question-4-training-a-cnn" class="level1">
<h1>Question 4: Training a CNN</h1>
<p>In ICA 17, you work through an example of training a CNN to perform image classification. The second half of the activity asks you to repeat the process for a new dataset.</p>
<p>Open the <a href="https://colab.research.google.com/drive/1E5RhAK0TgbZQgZwJBgpTgY8Njy_fTXZk?usp=sharing">ICA Colab Notebook</a>, make a copy for your team, and work through these sections:</p>
<ul>
<li>Step 4: Setting up the CNN</li>
<li>Step 5: Compiling the model</li>
<li>Step 6: Training the network</li>
<li>Step 7: Visualizing the results</li>
<li>Step 8: Trying another model</li>
</ul>
<section id="specifications-for-question-4" class="level2">
<h2 class="anchored" data-anchor-id="specifications-for-question-4">Specifications for Question 4</h2>
<p><strong>Base specifications:</strong></p>
<ul>
<li>Code block correctly builds the model similar to the CIFAR10 model</li>
<li>Code block correctly configures the model for training</li>
<li>Code block correctly runs the training algorithm</li>
<li>Code block(s) correctly display the loss and accuracy epoch-by-epoch</li>
<li>Final code blocks correctly set up the VGG-19 model and train it on the data</li>
</ul>
<p><strong>Extended specifications:</strong></p>
<ul>
<li>A link to the Colab Notebook is added to the README.md file in Github</li>
<li>Student names are added to the top of the Colab notebook</li>
<li>Any completed TODO comments have been removed</li>
</ul>
<p><strong>Ratings:</strong></p>
<ul>
<li>To receive a gold rating, fully complete 5 specifications, at least 4 base, and partially complete at least 1 more</li>
<li>To receive a silver rating, fully complete at least 4 specifications, at least 3 base, and partially complete at least 1 more</li>
<li>To receive a bronze rating, fully complete at least 3 specifications, at lesat 2 base, partially complete at least 1 more</li>
</ul>
</section>
</section>
<section id="question-5-experimenting-with-object-detection-and-segmentation-models" class="level1">
<h1>Question 5: Experimenting with Object Detection and Segmentation Models</h1>
<p>Complete the steps outlined in ICA 18.</p>
<section id="specifications-for-question-5" class="level2">
<h2 class="anchored" data-anchor-id="specifications-for-question-5">Specifications for Question 5</h2>
<p><strong>Base specifications:</strong></p>
<ul>
<li>Object detection:
<ul>
<li>Code block implements a loop over the images in the Images folder</li>
<li>Code correctly calls the model and saves the results</li>
<li>Code block iterates through the results and calls the <code>displayResults</code> function</li>
<li>Text block includes a written summary of interesting results: accuracies, inaccuracies, patterns in what is detected, or not</li>
</ul></li>
<li>Image segmentation:
<ul>
<li>Code block implements a loop over the images in the Images folder</li>
<li>Code correctly calls the model and saves the results</li>
<li>Code block iterates through the results and calls the <code>displayResults</code> function</li>
<li>Text block includes a written summary of interesting results: accuracies, inaccuracies, patterns in what is detected, or not</li>
</ul></li>
<li>Training YOLO:
<ul>
<li>Text block describes students’ experience with training YOLO on the Kitti dataset</li>
</ul></li>
</ul>
<p><strong>Extended specifications:</strong></p>
<ul>
<li>Top text block is updated to include students’ names</li>
<li>Any completed TODO comments have been removed</li>
</ul>
<p><strong>Ratings:</strong></p>
<ul>
<li>To receive a gold rating, complete at least 8 specifications in all, at least 7 of them base specifications.</li>
<li>To receive a silver rating, complete at least 7 specifications in all, at least 6 of them base.</li>
<li>To receive a bronze rating, complete at least 6 total specifications, at least 5 of them base.</li>
</ul>
</section>
</section>
<section id="question-6-evaluating-generative-ai-for-images" class="level1">
<h1>Question 6: Evaluating Generative AI for images</h1>
<p>For this question, you won’t be writing code. Training generative AI systems is beyond our capabilities, other than finetuning existing models. Instead, you will evaluate several different image-generating AI systems. You will briefly describe what you did, and what the results were. Be sure to include (1) your prompt or prompts and (2) screenshots or saved images of the generated images.</p>
<p><strong>Step 1: Read about good image prompt writing</strong></p>
<p>To get good results from a generative AI system, you need to give detailed descriptive prompts (requests). Read the source below to learn how to craft a good prompt.</p>
<p><a href="https://www.huit.harvard.edu/news/ai-prompts-images">Harvard University IT: Getting started with prompts for image-based Generative AI Tools</a></p>
<p><strong>Step 2: Create a starter prompt</strong></p>
<p>Decide on a single <em>safe for work</em> (family-friendly) prompt that you will use throughout this assignment (if you are a team, agree on the prompt, and maybe work through the first example with all members present.</p>
<p><strong>Step 3: Test three different AI image generators</strong></p>
<p>We will look at three different AI image generators:</p>
<ul>
<li>Chat-GPT, available at <a href="chatgpt.com">chatgpt.com</a></li>
<li>Nano Banana, available through the <a href="aistudio.google.com">Google AI Studio</a></li>
<li>Reve, available at <a href="app.reve.com">app.reve.com</a></li>
</ul>
<p>Pick one, and work through your original prompt, plus 2-3 modifications you use to get closer to what you had in mind (again, if you are a team, work through this first one together). Record the original prompt, and the exact wording for each modification, and the resulting image from each stage.</p>
<p>Next, try the other two systems, and use the same original prompt, and modifications prompts. Record all the images produced.</p>
<p><strong>Special note:</strong> Reve produces multiple images for each prompt. Pick the two you like best, and change your modification prompt to read: “Based on <span class="citation" data-cites="1">@1</span> and <span class="citation" data-cites="2">@2</span>, …” and then add your original wording.</p>
<p>Finally, write a report (see <a href="https://docs.google.com/document/d/1hVWWkAcC0EJKZZ6tLnILrQcENR8t9HgxAlxwrYHGPSs/edit?usp=sharing">Susan’s Sample GenAI Report</a> for an example) where you describe your prompts, and how what each AI system produced. Then analyze the results: which ones did you like better, and why?</p>
<p>Overall, how well does this kind of system work as an assistant to a human designer or artist? Is this an improvement upon “clip art” or downloading images from websites?</p>
<p>I chose these three AI systems based on <a href="https://zapier.com/blog/best-ai-image-generator/">an article by Harry Guinness</a> that talked about good current AI generators. I chose ones that had free modes. Note that ## Specifications for Question 6</p>
<p><strong>Base specifications:</strong></p>
<ul>
<li>Report clearly describes initial prompt, and prompt is detailed and appropriate</li>
<li>Report lists 2-3 modification prompts also used</li>
<li>Report shows all images produced for these prompts and all three AI systems</li>
<li>Report discusses positives and negatives of these specific results</li>
<li>Report analyzes which systems performed better or worse on this particular set of prompts</li>
</ul>
<p><strong>Ratings:</strong></p>
<ul>
<li>To receive a gold rating, complete fully at least 4 specifications in all, 1 partially</li>
<li>To receive a silver rating, complete fully at least 3 specifications in all, 1 partially</li>
<li>To receive a bronze rating, complete fully at least 2 total specifications, 2 partially</li>
</ul>
</section>
<section id="what-to-hand-in" class="level1">
<h1>What to hand in</h1>
<ul>
<li>For questions 1 and 2, submitting to the ICA 16 github repo will be sufficient. Note that for the homework, you <strong>must finish</strong> the whole ICA</li>
<li>For questions 3 and 4, your work will be in a colab notebook</li>
<li>For question 5, your work will be in a colab notebook</li>
<li>For question 6, your work will be a report</li>
</ul>
<p>In the assignment in Moodle, include a note telling me that you have submitted ICA 16, and include links to the two colab notebooks. You can either upload the report as a PDF file, or include a link to a Google Docs file.</p>
<p><strong>Make sure both notebooks and all Google Docs are shared with me, with commenting privileges!</strong></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
        for (let i=0; i<annoteTargets.length; i++) {
          const annoteTarget = annoteTargets[i];
          const targetCell = annoteTarget.getAttribute("data-target-cell");
          const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
          const contentFn = () => {
            const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
            if (content) {
              const tipContent = content.cloneNode(true);
              tipContent.classList.add("code-annotation-tip-content");
              return tipContent.outerHTML;
            }
          }
          const config = {
            allowHTML: true,
            content: contentFn,
            onShow: (instance) => {
              selectCodeLines(instance.reference);
              instance.reference.classList.add('code-annotation-active');
              window.tippy.hideAll();
            },
            onHide: (instance) => {
              unselectCodeLines();
              instance.reference.classList.remove('code-annotation-active');
            },
            maxWidth: 300,
            delay: [50, 0],
            duration: [200, 0],
            offset: [5, 10],
            arrow: true,
            appendTo: function(el) {
              return el.parentElement.parentElement.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'quarto',
            placement: 'right',
            popperOptions: {
              modifiers: [
              {
                name: 'flip',
                options: {
                  flipVariations: false, // true by default
                  allowedAutoPlacements: ['right'],
                  fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                },
              },
              {
                name: 'preventOverflow',
                options: {
                  mainAxis: false,
                  altAxis: false
                }
              }
              ]        
            }      
          };
          window.tippy(annoteTarget, config); 
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>